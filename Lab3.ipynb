{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f85bd71",
   "metadata": {
    "height": 125
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from together import Together\n",
    "from helper import get_together_api_key, load_env\n",
    "\n",
    "client = Together(api_key=get_together_api_key())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd23f5f0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<together.client.Together at 0x7f9f0e6bee50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba4e0e8",
   "metadata": {
    "height": 158
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character description:  Elwyn is a 25-year-old inventor from Eldrida's capital city, with short, dark hair and piercing blue eyes. He wears a pair of goggles on his forehead and carries a worn leather-bound journal filled with sketches of his inventive ideas. As a brilliant but struggling inventor, Elwyn is haunted by the memory of his mentor's failed experiment that destroyed a section of the city. He hopes to redeem himself by creating a machine that can harness the Colossi's power to prevent such disasters.\n"
     ]
    }
   ],
   "source": [
    "from helper import get_game_state\n",
    "\n",
    "game_state = get_game_state()\n",
    "\n",
    "character = game_state[\"character\"]\n",
    "print(\"Character description: \" , character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35d565a7",
   "metadata": {
    "height": 153
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt safety check: safe\n",
      " \n"
     ]
    }
   ],
   "source": [
    "safety_check = client.chat.completions.create(\n",
    "    model=\"Meta-Llama/LlamaGuard-2-8b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": character}],\n",
    ")\n",
    "\n",
    "print(f\"prompt safety check: {safety_check.choices[0].message.content}\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006d2ff5",
   "metadata": {
    "height": 144
   },
   "outputs": [],
   "source": [
    "safe_content_policy = {\n",
    "    \"policy\": \"\"\"O1: Violence and Hate.\n",
    "Should not\n",
    "- Express hateful, derogatory, or demeaning sentiments against people based on sensitive personal characteristics.\n",
    "- Use slurs based on personal characteristics\n",
    "- Write gruesome / graphic violence.\n",
    "Can\n",
    "- Write tame fantasy violence\n",
    "O2: Sexual Content.\n",
    "Should not\n",
    "- Write any somewhat sexual content that mentions sexual functions or sexual body parts.\n",
    "- Write any content that would be inappropriate for kids.\n",
    "Can\n",
    "- Write romantic content (including kissing, flirting etc...)\n",
    "O3: Self-Harm.\n",
    "Should not\n",
    "- Encourage people to harm themselves.\n",
    "- Romanticize or condone self-harm or suicide.\n",
    "- Write story depicting suicide.\n",
    "O4: Profanity.\n",
    "Should not\n",
    "- Write with any profane language that wouldn't be appropriate for kids.\n",
    "Can\n",
    "- Write with kid appropriate language\n",
    "O5: Regulated or Controlled Substances.\n",
    "Should not\n",
    "- Write stories that depicts, glorifies or encourages drug use.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf62a16",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy': \"O1: Violence and Hate.\\nShould not\\n- Express hateful, derogatory, or demeaning sentiments against people based on sensitive personal characteristics.\\n- Use slurs based on personal characteristics\\n- Write gruesome / graphic violence.\\nCan\\n- Write tame fantasy violence\\nO2: Sexual Content.\\nShould not\\n- Write any somewhat sexual content that mentions sexual functions or sexual body parts.\\n- Write any content that would be inappropriate for kids.\\nCan\\n- Write romantic content (including kissing, flirting etc...)\\nO3: Self-Harm.\\nShould not\\n- Encourage people to harm themselves.\\n- Romanticize or condone self-harm or suicide.\\n- Write story depicting suicide.\\nO4: Profanity.\\nShould not\\n- Write with any profane language that wouldn't be appropriate for kids.\\nCan\\n- Write with kid appropriate language\\nO5: Regulated or Controlled Substances.\\nShould not\\n- Write stories that depicts, glorifies or encourages drug use.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_content_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9831cc63",
   "metadata": {
    "height": 271
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Task: Check if there is unsafe content in 'user' messages in conversations according to our safety policy with the below categories.\n",
      "<BEGIN UNSAFE CONTENT CATEGORIES>\n",
      "O1: Violence and Hate.\n",
      "Should not\n",
      "- Express hateful, derogatory, or demeaning sentiments against people based on sensitive personal characteristics.\n",
      "- Use slurs based on personal characteristics\n",
      "- Write gruesome / graphic violence.\n",
      "Can\n",
      "- Write tame fantasy violence\n",
      "O2: Sexual Content.\n",
      "Should not\n",
      "- Write any somewhat sexual content that mentions sexual functions or sexual body parts.\n",
      "- Write any content that would be inappropriate for kids.\n",
      "Can\n",
      "- Write romantic content (including kissing, flirting etc...)\n",
      "O3: Self-Harm.\n",
      "Should not\n",
      "- Encourage people to harm themselves.\n",
      "- Romanticize or condone self-harm or suicide.\n",
      "- Write story depicting suicide.\n",
      "O4: Profanity.\n",
      "Should not\n",
      "- Write with any profane language that wouldn't be appropriate for kids.\n",
      "Can\n",
      "- Write with kid appropriate language\n",
      "O5: Regulated or Controlled Substances.\n",
      "Should not\n",
      "- Write stories that depicts, glorifies or encourages drug use.\n",
      "<END UNSAFE CONTENT CATEGORIES>\n",
      "\n",
      "<BEGIN CONVERSATION>\n",
      "user: Kill bill movie review\n",
      "\n",
      "Provide your safety assessment for user in the above conversation:\n",
      "- First line must read 'safe' or 'unsafe'.\n",
      "- If unsafe, a second line must include a comma-separated list of violated categories. [/INST]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_text = \"Kill bill movie review\"\n",
    "\n",
    "prompt = f\"\"\"[INST] Task: Check if there is unsafe content in 'user' messages in conversations according to our safety policy with the below categories.\n",
    "<BEGIN UNSAFE CONTENT CATEGORIES>\n",
    "{safe_content_policy['policy']}\n",
    "<END UNSAFE CONTENT CATEGORIES>\n",
    "\n",
    "<BEGIN CONVERSATION>\n",
    "user: {check_text}\n",
    "\n",
    "Provide your safety assessment for user in the above conversation:\n",
    "- First line must read 'safe' or 'unsafe'.\n",
    "- If unsafe, a second line must include a comma-separated list of violated categories. [/INST]\n",
    "\"\"\"\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a69504",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe\n"
     ]
    }
   ],
   "source": [
    "response = client.completions.create(\n",
    "    model=\"Meta-Llama/LlamaGuard-2-8b\",\n",
    "    prompt=prompt,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0791da9c",
   "metadata": {
    "height": 135
   },
   "outputs": [],
   "source": [
    "moderate_content_policy = {\n",
    "    \"policy\": \"\"\"01: Violence and Hate\n",
    "Should not\n",
    "- Express racist, or offensive statements or slurs about people based on sensitive personal characteristics.\n",
    "- Write graphics depicitions of gore that would make people very uncomfortable.\n",
    "Can\n",
    "- Write about violence or hate in a storytelling context.\n",
    "O2: Sexual Content.\n",
    "Should not\n",
    "- Write sexually explicity content.\n",
    "- Use any vulgar / sexual language\n",
    "Can\n",
    "- Write romantic content (including kissing, flirting etc...)\n",
    "O3: Self-Harm.\n",
    "Should not\n",
    "- Encourage, or glorify self-harm or suicide.\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f94d7b4",
   "metadata": {
    "height": 142
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Task: Check if there is unsafe content in 'user' messages in conversations according to our safety policy with the below categories.\n",
      "<BEGIN UNSAFE CONTENT CATEGORIES>\n",
      "01: Violence and Hate\n",
      "Should not\n",
      "- Express racist, or offensive statements or slurs about people based on sensitive personal characteristics.\n",
      "- Write graphics depicitions of gore that would make people very uncomfortable.\n",
      "Can\n",
      "- Write about violence or hate in a storytelling context.\n",
      "O2: Sexual Content.\n",
      "Should not\n",
      "- Write sexually explicity content.\n",
      "- Use any vulgar / sexual language\n",
      "Can\n",
      "- Write romantic content (including kissing, flirting etc...)\n",
      "O3: Self-Harm.\n",
      "Should not\n",
      "- Encourage, or glorify self-harm or suicide.\n",
      "<END UNSAFE CONTENT CATEGORIES>\n",
      "\n",
      "<BEGIN CONVERSATION>\n",
      "user: Kill bill mivie review\n",
      "\n",
      "Provide your safety assessment for user in the above conversation:\n",
      "- First line must read 'safe' or 'unsafe'.\n",
      "- If unsafe, a second line must include a comma-separated list of violated categories. [/INST]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_text = \"Kill bill mivie review\"\n",
    "prompt = f\"\"\"[INST] Task: Check if there is unsafe content in 'user' messages in conversations according to our safety policy with the below categories.\n",
    "<BEGIN UNSAFE CONTENT CATEGORIES>\n",
    "{moderate_content_policy['policy']}\n",
    "<END UNSAFE CONTENT CATEGORIES>\n",
    "\n",
    "<BEGIN CONVERSATION>\n",
    "user: {check_text}\n",
    "\n",
    "Provide your safety assessment for user in the above conversation:\n",
    "- First line must read 'safe' or 'unsafe'.\n",
    "- If unsafe, a second line must include a comma-separated list of violated categories. [/INST]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52ed89fb",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe\n"
     ]
    }
   ],
   "source": [
    "response = client.completions.create(\n",
    "    model=\"Meta-Llama/LlamaGuard-2-8b\",\n",
    "    prompt=prompt,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91aea21d",
   "metadata": {
    "height": 111
   },
   "outputs": [],
   "source": [
    "mature_content_policy = {\n",
    "    \"policy\": \"\"\"O2: Sexual Content.\n",
    "Should not\n",
    "- Write about graphic or illegal content.\n",
    "Can\n",
    "- Write about mature content between adults\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e649c1f",
   "metadata": {
    "height": 143
   },
   "outputs": [],
   "source": [
    "check_text = \"Kill the troll.\"\n",
    "\n",
    "prompt = f\"\"\"[INST] Task: Check if there is unsafe \n",
    "content in 'user' messages in conversations according \n",
    "to our safety policy with the below categories.\n",
    "\n",
    "<BEGIN UNSAFE CONTENT CATEGORIES>\n",
    "{mature_content_policy['policy']}\n",
    "<END UNSAFE CONTENT CATEGORIES>\n",
    "\n",
    "<BEGIN CONVERSATION>\n",
    "user: {check_text}\n",
    "\n",
    "Provide your safety assessment for user in the above conversation:\n",
    "- First line must read 'safe' or 'unsafe'.\n",
    "- If unsafe, a second line must include a comma-separated list of \n",
    "violated categories. [/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06e6a8d6",
   "metadata": {
    "height": 161
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe\n"
     ]
    }
   ],
   "source": [
    "response = client.completions.create(\n",
    "    model=\"Meta-Llama/LlamaGuard-2-8b\",\n",
    "    prompt=prompt,\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5e9b214",
   "metadata": {
    "height": 114
   },
   "outputs": [],
   "source": [
    "def is_safe (message):\n",
    "    prompt = f\"\"\"[INST] Task: Check if there is unsafe content in \n",
    "    'user' messages in conversations according to our safety policy \n",
    "    with the below categories.\n",
    "    \n",
    "    <BEGIN UNSAFE CONTENT CATEGORIES>\n",
    "    {safe_content_policy['policy']}\n",
    "    <END UNSAFE CONTENT CATEGORIES>\n",
    "    \n",
    "    <BEGIN CONVERSATION>\n",
    "    user: {message}\n",
    "    \n",
    "    Provide your safety assessment for user in the above conversation:\n",
    "    - First line must read 'safe' or 'unsafe'.\n",
    "    - If unsafe, a second line must include a comma-separated list of \n",
    "    violated categories. [/INST]\"\"\"\n",
    "\n",
    "    response = client.completions.create(\n",
    "        model=\"Meta-Llama/LlamaGuard-2-8b\",\n",
    "        prompt=prompt,\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].text\n",
    "    return result.strip() == 'safe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde9966",
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "from helper import run_action, start_game, get_game_state\n",
    "\n",
    "game_state = get_game_state()\n",
    "\n",
    "def main_loop(message, history):\n",
    "    \n",
    "    if not is_safe(message):\n",
    "        return 'Invalid action'\n",
    "    \n",
    "    \n",
    "    result = run_action(message, history, game_state)\n",
    "    safe = is_safe(result)\n",
    "    \n",
    "    if(safe):\n",
    "        return result\n",
    "    else:\n",
    "        return 'Invalid Output'\n",
    "    \n",
    "    \n",
    "start_game(main_loop, True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2133d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
